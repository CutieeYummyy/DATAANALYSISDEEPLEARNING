{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1nHyAHfBv-MQgEw2E-KCd3k6OZGDCc8mL",
      "authorship_tag": "ABX9TyNuj8FitjzHyBN5VAUFY2NT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CutieeYummyy/DATAANALYSISDEEPLEARNING/blob/main/TH%E1%BB%B0C_H%C3%80NH_BU%E1%BB%94I_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#Problem 1\n",
        "# Thêm header vào DataFrame để diễn giải dữ liệu\n",
        "column_names = ['ID', 'Name', 'Age', 'Weight', 'm0006', 'm0612', 'm1218', 'f0006', 'f0612', 'f1218']\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(r'/patient_heart_rate.csv', names=column_names, on_bad_lines='skip', skiprows=1)\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(df.head())\n",
        "\n",
        "#Problem 2\n",
        "df[[\"FirstName\", \"LastName\"]] = df[\"Name\"].str.split(\" \", n=1, expand=True)\n",
        "df= df.drop('Name', axis=1)\n",
        "#print(df)\n",
        "\n",
        "#Problem 3\n",
        "#Get the Weight column\n",
        "weight = df[\"Weight\"]\n",
        "def convert_weight(weight):\n",
        "    if isinstance(weight, str):\n",
        "        if 'lbs' in weight:\n",
        "            weight = weight[:-3]\n",
        "            return str(int(float(weight) / 2.2)) + 'kgs'\n",
        "    return weight\n",
        "\n",
        "# Áp dụng hàm chuyển đổi cho cột 'Weight' trên bản sao DataFrame\n",
        "df[\"Weight\"] = weight.apply(convert_weight)\n",
        "#print(df)\n",
        "\n",
        "#Problem 4\n",
        "df.dropna(how='all', inplace=True)\n",
        "#print(df)\n",
        "\n",
        "#Problem 5\n",
        "df=df.drop_duplicates(subset=[\"FirstName\",\"LastName\",\"Age\",\"Weight\"])\n",
        "#print(df)\n",
        "\n",
        "#Problem 6\n",
        "df.FirstName.replace({r'[\\x00-\\x7F]+':''}, regex=True, inplace=True)\n",
        "df.LastName.replace({r'[\\x00-\\x7F]+':''}, regex=True, inplace=True)\n",
        "#print(df)\n",
        "\n",
        "#Problem 7\n",
        "#Deletion: Remove records with missing values\n",
        "df = df.dropna(subset=['Age', 'Weight'])\n",
        "#print(\"\\nDataFrame after Deletion:\")\n",
        "#print(df.head())\n",
        "#Dummy substitution: Replace missing values with a dummy but valid value:e.g.: 0 for numerical values\n",
        "df_dummy = df.fillna({'Age': 0, 'Weight': '0kgs'})\n",
        "#print(\"\\nDataFrame after Dummy substitution:\")\n",
        "#print(df_dummy.head())\n",
        "#Mean substitution: Replace the missing values with the mean\n",
        "df_mean = df.copy()\n",
        "df_mean['Age'] = df_mean['Age'].fillna(df_mean['Age'].mean())\n",
        "df_mean['Weight'] = df_mean['Weight'].fillna(df_mean['Weight'].apply(lambda x: int(x[:-3]) if isinstance(x, str) else x).mean())\n",
        "df_mean['Weight'] = df_mean['Weight'].astype(str) + 'kgs'\n",
        "#print(\"\\nDataFrame after Mean substitution:\")\n",
        "#print(df_mean.head())\n",
        "#Frequent substitution: Replace the missing values with the most frequent item.\n",
        "df_frequent = df.copy()\n",
        "df_frequent['Age'] = df_frequent['Age'].fillna(df_frequent['Age'].mode()[0])\n",
        "df_frequent['Weight'] = df_frequent['Weight'].fillna(df_frequent['Weight'].mode()[0])\n",
        "#print(\"\\nDataFrame after Frequent substitution:\")\n",
        "#print(df_frequent.head())\n",
        "#Yêu cầu\n",
        "# Thống kê thông tin dữ liệu thiếu\n",
        "missing_info = df[['Age', 'Weight']].isnull().sum()\n",
        "missing_info_percentage = df[['Age', 'Weight']].isnull().mean() * 100\n",
        "\n",
        "#print(\"Missing values count:\\n\", missing_info)\n",
        "#print(\"Missing values percentage:\\n\", missing_info_percentage)\n",
        "\n",
        "#Problem 8\n",
        "#Mekt the Sex+ time range column in single column\n",
        "df = pd.melt(df, id_vars=['ID','Age','Weight', 'FirstName', 'LastName'], var_name='sex_and_time').sort_values(['ID','Age','Weight','FirstName','LastName'])\n",
        "#Extract Sex, Hour Lower bound and Hour upper bound group\n",
        "tmp_df = df[\"sex_and_time\"].str.extract(r\"(\\D)(\\d+)(\\d{2})\", expand=True) # Added opening parenthesis before \\D to balance the expression\n",
        "#Name columns\n",
        "tmp_df.columns = ['Sex', 'Hour_Lower', 'Hour_Upper']\n",
        "#Create Time column based in 'Hour_Lower' and \"hour_Upper\" columns\n",
        "tmp_df[\"Time\"]=tmp_df[\"Hour_Lower\"]+ \"-\" +tmp_df[\"Hour_Upper\"]\n",
        "#merge\n",
        "df = pd.concat([df, tmp_df], axis=1)\n",
        "#Drop unneccessary columns and rows\n",
        "df = df.drop(['sex_and_time','Hour_Lower','Hour_Upper'], axis=1)\n",
        "df = df.dropna()\n",
        "df.to_csv('outputcleanup.csv', index=False)\n",
        "#print(df)\n",
        "\n",
        "#Problem 9\n",
        "\n",
        "# Calculate the missing data percentage on blood pressure columns\n",
        "missing_bp = df[['m0006', 'm0612', 'm1218', 'f0006', 'f0612', 'f1218']].isnull().mean() * 100\n",
        "print(\"Missing data percentage on blood pressure columns:\")\n",
        "print(missing_bp)\n",
        "\n",
        "# Function to replace missing blood pressure values\n",
        "\n",
        "def replace_missing_bp(df):\n",
        "    for col in ['m0006', 'm0612', 'm1218', 'f0006', 'f0612', 'f1218']:\n",
        "        for i in range(len(df)):\n",
        "            if pd.isna(df.loc[i, col]):\n",
        "                replaced = False\n",
        "\n",
        "                # 1) Replace with average of immediate neighbors\n",
        "                if i > 0 and i < len(df) - 1 and pd.notnull(df.loc[i-1, col]) and pd.notnull(df.loc[i+1, col]):\n",
        "                    neighbor1 = float(df.loc[i-1, col]) if pd.notnull(df.loc[i-1, col]) and isinstance(df.loc[i-1, col], str) else df.loc[i-1, col]\n",
        "                    neighbor2 = float(df.loc[i+1, col]) if pd.notnull(df.loc[i+1, col]) and isinstance(df.loc[i+1, col], str) else df.loc[i+1, col]\n",
        "                    df.loc[i, col] = (neighbor1 + neighbor2) / 2\n",
        "                    replaced = True\n",
        "\n",
        "                # 2) Replace with average of two previous values\n",
        "                if not replaced and i > 1 and pd.notnull(df.loc[i-1, col]) and pd.notnull(df.loc[i-2, col]):\n",
        "                    prev1 = float(df.loc[i-1, col]) if pd.notnull(df.loc[i-1, col]) and isinstance(df.loc[i-1, col], str) else df.loc[i-1, col]\n",
        "                    prev2 = float(df.loc[i-2, col]) if pd.notnull(df.loc[i-2, col]) and isinstance(df.loc[i-2, col], str) else df.loc[i-2, col]\n",
        "                    df.loc[i, col] = (prev1 + prev2) / 2\n",
        "                    replaced = True\n",
        "\n",
        "                # 3) Replace with average of two subsequent values\n",
        "                if not replaced and i < len(df) - 2 and pd.notnull(df.loc[i+1, col]) and pd.notnull(df.loc[i+2, col]):\n",
        "                    next1 = float(df.loc[i+1, col]) if pd.notnull(df.loc[i+1, col]) and isinstance(df.loc[i+1, col], str) else df.loc[i+1, col]\n",
        "                    next2 = float(df.loc[i+2, col]) if pd.notnull(df.loc[i+2, col]) and isinstance(df.loc[i+2, col], str) else df.loc[i+2, col]\n",
        "                    df.loc[i, col] = (next1 + next2) / 2\n",
        "                    replaced = True\n",
        "                # 4) Replace with average of all values for that person\n",
        "                if not replaced:\n",
        "                    person_bp_values = df.loc[i, ['m0006', 'm0612', 'm1218', 'f0006', 'f0612', 'f1218']].dropna().astype(float)\n",
        "                    if len(person_bp_values) > 0:\n",
        "                        df.loc[i, col] = person_bp_values.mean()\n",
        "                    else:\n",
        "                        # 5) Replace with average of all values for that gender group\n",
        "                        gender_group = col[0]\n",
        "                        gender_bp_values = df[df['gender'] == gender_group][['m0006', 'm0612', 'm1218', 'f0006', 'f0612', 'f1218']].stack().astype(float)\n",
        "                        if len(gender_bp_values) > 0:\n",
        "                            df.loc[i, col] = gender_bp_values.mean()\n",
        "                        else:\n",
        "                            # 6) Replace with overall average\n",
        "                            overall_bp_values = df[['m0006', 'm0612', 'm1218', 'f0006', 'f0612', 'f1218']].stack().astype(float)\n",
        "                            df.loc[i, col] = overall_bp_values.mean()\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply the function to replace missing blood pressure values\n",
        "df = replace_missing_bp(df)\n",
        "\n",
        "# Display the dataframe after replacing missing blood pressure values\n",
        "print(\"\\nDataFrame after replacing missing blood pressure values:\")\n",
        "print(df.head())\n",
        "\n",
        "# Problem 10\n",
        "\n",
        "# Drop any rows with missing values in the dataset\n",
        "df_clean = df.dropna()\n",
        "\n",
        "# Reindex the cleaned dataframe\n",
        "df_clean.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Save the cleaned data to a CSV file\n",
        "df_clean.to_csv('patient_data_clean.csv', index=False)\n",
        "\n",
        "print(\"Cleaned data saved to patient_data_clean.csv successfully.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "AMh_wDKqlDNa",
        "outputId": "a615f006-7f7e-4fc4-cdcb-02505e2be5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ID            Name   Age      Weight m0006 m0612 m1218 f0006 f0612 f1218\n",
            "0  2.0     Donald Duck  34.0   154.89lbs     -     -     -    85    84    76\n",
            "1  3.0      Mini Mouse  16.0         NaN     -     -     -    65    69    72\n",
            "2  4.0  Scrooge McDuck   NaN       78kgs    78    79    72     -     -     -\n",
            "3  5.0    Pink Panther  54.0  198.658lbs     -     -     -    69   NaN    75\n",
            "4  6.0     Huey McDuck  52.0      189lbs     -     -     -    68    75    72\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['m0006', 'm0612', 'm1218', 'f0006', 'f0612', 'f1218'], dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-0ca8b14fc2ae>\u001b[0m in \u001b[0;36m<cell line: 96>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# Calculate the missing data percentage on blood pressure columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mmissing_bp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'm0006'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'm0612'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'm1218'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f0006'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f0612'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1218'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Missing data percentage on blood pressure columns:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_bp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3766\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3767\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3769\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5875\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5877\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5879\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5936\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5937\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5938\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5940\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['m0006', 'm0612', 'm1218', 'f0006', 'f0612', 'f1218'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    }
  ]
}